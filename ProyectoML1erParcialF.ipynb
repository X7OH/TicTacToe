{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab import userdata\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Obtener el token desde los secretos\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Nombre del modelo\n",
        "model_name = \"bigscience/bloom-560m\"\n",
        "\n",
        "# Verificar si la GPU está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando el dispositivo: {device}\")\n",
        "\n",
        "# Cargar el tokenizador y el modelo usando el token desde secrets\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, token=hf_token)"
      ],
      "metadata": {
        "id": "urPwnvEvY0j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener tu token de Hugging Face desde Google Colab\n",
        "hf_token2 = userdata.get('EHF_TOKEN2')\n",
        "\n",
        "# Nombre del modelo\n",
        "model_name = \"distilbert/distilgpt2\"  # Puedes cambiarlo por otro modelo compatible\n",
        "\n",
        "# Cargar el tokenizador y modelo con el token de Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token)"
      ],
      "metadata": {
        "id": "ujSl99DtYtk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-pSMxrEYn_Y"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Clase TicTacToe para manejar el juego\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = [' ' for _ in range(9)]  # 9 celdas vacías\n",
        "        self.current_turn = 'X'  # 'X' empieza primero\n",
        "\n",
        "    def _printBoard(self):\n",
        "        for i in range(0, 9, 3):\n",
        "            print(f\"{self.board[i]} | {self.board[i+1]} | {self.board[i+2]}\")\n",
        "            if i < 6:\n",
        "                print(\"---------\")\n",
        "\n",
        "    def _checkWin(self, mark):\n",
        "        win_conditions = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Filas\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columnas\n",
        "            [0, 4, 8], [2, 4, 6]             # Diagonales\n",
        "        ]\n",
        "        for condition in win_conditions:\n",
        "            if all(self.board[i] == mark for i in condition):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _getEmptyCells(self):\n",
        "        return [i for i, cell in enumerate(self.board) if cell == ' ']\n",
        "\n",
        "    def playMove(self, position, mark):\n",
        "        if self.board[position] == ' ':\n",
        "            self.board[position] = mark\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def isFull(self):\n",
        "        return ' ' not in self.board\n",
        "\n",
        "def aiMove(model, tokenizer, device, board, mark):\n",
        "    # Convertir el estado del tablero en un formato de texto para la IA\n",
        "    board_state = ''.join(board)\n",
        "    prompt = f\"El tablero de TicTacToe es: {board_state}. ¿Dónde debe colocar la ficha '{mark}'?\"\n",
        "\n",
        "    # Tokenizar la entrada\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generar la respuesta del modelo\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs['input_ids'], max_length=50)\n",
        "\n",
        "    # Decodificar la salida\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(\"Respuesta de la IA:\", response)\n",
        "\n",
        "    # Interpretar la respuesta para obtener la jugada\n",
        "    move = None\n",
        "    for i in range(9):\n",
        "        if f\"{i}\" in response:\n",
        "            move = i\n",
        "            break\n",
        "\n",
        "    # Validar si la posición está dentro del rango permitido\n",
        "    if move is not None and 0 <= move < 9 and board[move] == ' ':\n",
        "        return move\n",
        "    else:\n",
        "        print(\"Movimiento inválido, eligiendo una posición aleatoria.\")\n",
        "        return random.choice([i for i in range(9) if board[i] == ' '])\n",
        "\n",
        "\n",
        "# Función evaluadora\n",
        "def evaluateMove(board, position, mark):\n",
        "    if board[position] == ' ':\n",
        "        return \"Válida\"\n",
        "    return \"Inválida\"\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Inicialización de modelos\n",
        "hf_token = userdata.get('HF_TOKEN')  # jugador 1\n",
        "hf_token2 = userdata.get('HF_TOKEN2')  # jugador 2\n",
        "ehf_token = userdata.get('EHF_TOKEN') # evaluador\n",
        "\n",
        "model_name_player1 = \"bigscience/bloom-560m\"\n",
        "model_name_player2 = \"TinyLlama/TinyLlama_v1.1\"\n",
        "model_name_evaluator = \"distilgpt2\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Cargar modelos\n",
        "tokenizer_p1 = AutoTokenizer.from_pretrained(model_name_player1, token=hf_token)\n",
        "model_p1 = AutoModelForCausalLM.from_pretrained(model_name_player1, token=hf_token).to(device)\n",
        "\n",
        "tokenizer_p2 = AutoTokenizer.from_pretrained(model_name_player2, token=hf_token2)\n",
        "model_p2 = AutoModelForCausalLM.from_pretrained(model_name_player2, token=hf_token2).to(device)\n",
        "\n",
        "tokenizer_eval = AutoTokenizer.from_pretrained(model_name_evaluator, token=ehf_token)\n",
        "model_eval = AutoModelForCausalLM.from_pretrained(model_name_evaluator, token=ehf_token).to(device)\n",
        "\n",
        "\n",
        "# def evaluateMove(model, tokenizer, device, board, position, mark):\n",
        "#     # Convertir el estado del tablero en un formato de texto para la IA\n",
        "#     board_state = ''.join(board)\n",
        "#     prompt = f\"El tablero de TicTacToe es: {board_state}. ¿Cuál es la próxima jugada válida para '{mark}'?\"\n",
        "\n",
        "#     # Tokenizar la entrada\n",
        "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "#     # Generar la respuesta del modelo\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model.generate(inputs['input_ids'], max_length=50)\n",
        "\n",
        "#     # Decodificar la salida\n",
        "#     response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "#     print(\"Respuesta de la IA Evaluadora:\", response)\n",
        "\n",
        "#     # Interpretar la respuesta para determinar si la jugada es válida\n",
        "#     if \"válida\" in response.lower():\n",
        "#         return \"Válida\"\n",
        "#     else:\n",
        "#         return \"Inválida\"\n",
        "def evaluateMove(model, tokenizer, device, board, position, mark):\n",
        "    # Convertir el estado del tablero en un formato de texto para la IA\n",
        "    board_state = ''.join(board)\n",
        "\n",
        "    # Crear un prompt que pregunte si la jugada en la posición actual es válida\n",
        "    prompt = f\"El tablero de TicTacToe es: {board_state}. ¿Cuál es la próxima jugada válida para '{mark}'?\"\n",
        "\n",
        "    # Tokenizar la entrada\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generar la respuesta del modelo\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs['input_ids'], max_length=50)\n",
        "\n",
        "    # Decodificar la salida\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(\"Respuesta de la IA Evaluadora:\", response)\n",
        "\n",
        "    # Interpretar la respuesta para determinar si la jugada es válida\n",
        "    if \"válida\" in response.lower():\n",
        "        return \"Válida\"\n",
        "    else:\n",
        "        return \"Inválida\"\n",
        "\n",
        "# Simular partidas\n",
        "game = TicTacToe()\n",
        "n_games = 10\n",
        "wins_p1, wins_p2 = 0, 0\n",
        "\n",
        "for game_num in range(1, n_games + 1):\n",
        "    print(f\"\\nPartida {game_num}:\")\n",
        "    game.board = [' ' for _ in range(9)]\n",
        "    game.current_turn = 'X'\n",
        "\n",
        "    while not game.isFull():\n",
        "        if game.current_turn == 'X':\n",
        "            print(\"Turno del jugador IA 1 (X):\")\n",
        "            move = aiMove(model_p1, tokenizer_p1, device, game.board, 'X')\n",
        "            evaluation = evaluateMove(model_eval, tokenizer_eval, device, game.board, move, 'X')\n",
        "            # print(f\"Evaluación de la jugada: {evaluation}\")\n",
        "            if evaluation == \"Válida\" and game.playMove(move, 'X'):\n",
        "                game._printBoard()\n",
        "                if game._checkWin('X'):\n",
        "                    print(\"¡Jugador 1 (X) ha ganado!\")\n",
        "                    wins_p1 += 1\n",
        "                    break\n",
        "            game.current_turn = 'O'\n",
        "\n",
        "        elif game.current_turn == 'O':\n",
        "            print(\"Turno del jugador IA 2 (O):\")\n",
        "            move = aiMove(model_p2, tokenizer_p2, device, game.board, 'O')\n",
        "            evaluation = evaluateMove(model_eval, tokenizer_eval, device, game.board, move, 'O')\n",
        "            # print(f\"Evaluación de la jugada: {evaluation}\")\n",
        "            if evaluation == \"Válida\" and game.playMove(move, 'O'):\n",
        "                game._printBoard()\n",
        "                if game._checkWin('O'):\n",
        "                    print(\"¡Jugador 2 (O) ha ganado!\")\n",
        "                    wins_p2 += 1\n",
        "                    break\n",
        "            game.current_turn = 'X'\n",
        "\n",
        "# Mostrar estadísticas finales\n",
        "print(\"\\nEstadísticas:\")\n",
        "print(f\"Jugador 1 (X) - Victorias: {wins_p1}\")\n",
        "print(f\"Jugador 2 (O) - Victorias: {wins_p2}\")\n",
        "print(f\"Porcentaje de victorias del Jugador 1: {wins_p1 / n_games * 100}%\")\n",
        "print(f\"Porcentaje de victorias del Jugador 2: {wins_p2 / n_games * 100}%\")"
      ]
    }
  ]
}